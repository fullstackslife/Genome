# Phase 2 Design Specification: Cell State Abstraction (Revised)

**Status**: Design-only specification. No implementation. Revised to incorporate feedback from the hostile peer review and clarify ambiguous or risky elements.

**Phase 1 Dependency**: Phase 2 consumes only Phase 1 outputs (embeddings + metadata). It does NOT ingest raw RNA expression data.

**Scope**: Define how to discover and describe cell states as neutral, probabilistic abstractions of patterns in latent embedding space. Phase 2 remains purely descriptive and does not model state transitions (that is Phase 3).

---

## 1. Purpose of Phase 2

### 1.1 What "Cell State" Means

A **cell state** is an abstract configuration of samples as represented by their latent embeddings. A state is:

- **Latent** – defined in the embedding space, not directly observable in gene expression or biology.
- **Probabilistic** – samples can belong to multiple states with assignment probabilities.
- **Descriptive** – it describes statistical patterns; it does not infer biological meaning.
- **Versioned** – state definitions are versioned to track changes over time.
- **Non‑diagnostic** – states carry no medical or clinical interpretation.

### 1.2 How It Differs from Labels

**Labels** are external annotations such as "tissue type" or "condition." Phase 2 does not use labels.

**Cell states** are discovered purely from data, using unsupervised methods in latent space. They are not tied to external knowledge or annotations.

### 1.3 How It Differs from Diagnoses and Conditions

**Diagnoses/conditions** imply medical or biological states. Phase 2 explicitly avoids medical interpretation or causal inference.

**Cell states** are mathematical abstractions that describe patterns in embeddings. They never indicate health, disease, or prognosis.

### 1.4 Why It Is an Abstraction, Not a Conclusion

- States represent simplified summaries of complex latent patterns.
- States are inferences with uncertainty, not facts.
- States enable pattern recognition and comparison without classification, diagnosis, or treatment guidance.

---

## 2. Inputs

### 2.1 Allowed Inputs

Phase 2 must only consume Phase 1 outputs:

1. **Embeddings** – latent embedding vectors (samples × embedding_dim) generated by the Phase 1 foundation model, stored in `embeddings/{ingestion_id}/embeddings.parquet`.

2. **Projection Metadata** – coordinates (PCA, UMAP) and method parameters for visualization. Not used for state inference.

3. **Normalization Metadata** – normalization parameters (log base, batch correction flags, random seed) for reproducibility tracking. Not used for state inference.

4. **Model Version Info** – identifier of the Phase 1 model and its latent_dim to enforce compatibility.

5. **Ingestion Metadata** – sample identifiers (non‑identifying), gene counts, ingestion timestamp, and format (bulk vs. single‑cell).

### 2.2 Input Validation Requirements

Implementations must validate inputs before state inference:

- **Embedding Dimension Consistency** – the dimensionality of embeddings must match the latent_dim recorded in model version metadata. Mismatches cause a hard failure.

- **Required Metadata Presence** – all mandatory fields (embedding vectors, model version, sample IDs, gene counts, ingestion timestamp) must be present. Missing data results in an error.

- **Numeric Integrity** – embeddings must be numeric, finite values (no NaN or ±Inf). Any non‑numeric values cause a failure.

- **Sample Count Match** – the number of embedding vectors must match the sample count in the ingestion metadata. Discrepancies cause an error.

- **Version Compatibility** – embeddings must originate from the same model version. Mixing embeddings from different versions is forbidden.

- **Error Handling** – failures must return clear, neutral error messages. No silent corrections. The platform should fail fast and inform the caller why the request is invalid.

### 2.3 Forbidden Inputs

Phase 2 must never accept or use:

1. **Raw Expression Matrices** – gene expression counts, normalized values, or any data pre‑embedding. Raw data remains in Phase 1.

2. **Clinical Labels** – external annotations (e.g., tissue type, condition), patient identifiers, experimental conditions, or medical classifications.

3. **External Annotations** – gene ontology terms, pathway annotations, literature‑derived labels, or any metadata beyond embeddings and model metadata.

4. **Disease Terms** – any medical terminology, health classifications, diagnostic labels, or treatment information.

**Rationale**: To remain unsupervised and non‑medical, Phase 2 cannot include external or clinical knowledge.

---

## 3. Cell State Object Definition (Conceptual)

This section defines the conceptual properties of a state and a state model. It is not a code or JSON schema.

### 3.1 Core Properties of a State

#### state_id

- Unique identifier for a state within a particular state model version.
- **Format**: `state_{index}_v{major}.{minor}` (e.g., `state_3_v1.0`). The state index is an integer starting at 1 within each version.
- **Uniqueness**: State IDs are unique only within their model version. Two different versions can have a `state_3`, but these represent different definitions.

#### defining_features

- A list of indices referring to dimensions in the embedding space whose statistical distributions most distinguish this state from the overall embedding distribution.
- **Interpretation**: Features are embedding dimensions, not genes. They identify latent directions where samples assigned to this state differ significantly (e.g., via z‑score or mutual information) from the global distribution.
- **Guidance**: Use statistical criteria (e.g., top‑k dimensions with highest contribution to cluster separation). Do not interpret feature indices as biological attributes. "High" values are relative to the distribution of that dimension across all samples.

#### stability_score

- A float in [0, 1] indicating how tightly samples assigned to this state cluster in embedding space. Higher values indicate tighter clustering (lower variance).
- **Calculation**: Derived from a statistical dispersion metric (e.g., inverse normalized intra‑cluster variance). Implementation details are decided later.
- **Disclaimer**: A stability score is a mathematical measure of cluster compactness. It has no biological or medical meaning. All outputs containing stability scores must include a disclaimer: "Stability is a statistical property of embeddings and does not indicate health, disease, normality, or abnormality."

#### variance_profile

- A vector describing variance of samples in each embedding dimension for this state. It helps identify which dimensions contribute most to state spread.
- **Not** a measure of deviation from "normal." It only quantifies spread within the state in latent space.

#### assignment_uncertainty (formerly "Confidence Interval")

- A distribution or range capturing the uncertainty of assigning samples to this state. It quantifies the variability of assignment probability across samples.
- **Representation**: Could be the 5th–95th percentile of assignment probabilities or other statistical bounds. Implementation chooses the representation.
- **Purpose**: Provide a measure of how confidently the model can assign samples to this state. It is not a medical confidence measure.

#### assignment_certainty (formerly "Confidence")

- A per‑sample value summarizing the certainty with which a sample belongs to its assigned primary state. It can be defined as the maximum state assignment probability for each sample.
- **Renaming** avoids confusion with assignment_uncertainty.

#### version

- A semantic version string `v{major}.{minor}` (e.g., `v1.0`). The major version increments when state definitions change significantly; the minor version increments for minor refinements (e.g., threshold changes).
- State model version applies to the entire set of states. Individual states are not independently versioned.

#### change_log

- A descriptive record of modifications from the previous version. It lists the reasons for version change, such as new data added or threshold adjustments.

### 3.2 State Model Structure

A **state model** is a versioned collection of states inferred from a specific embedding dataset.

- Contains multiple states (typical range: 3–50; see scale guidance).
- Each state has the core properties described above.
- The model is immutable once created. New data or methodological changes require a new version of the state model.
- States within a model are mutually exclusive in their highest‑probability assignments but overlap at boundaries (soft assignment).

### 3.3 Sample–State Assignment

Each sample has a probability vector over all states. Probabilities sum to 1.0.

- **Primary state**: state with the highest assignment probability.
- **Active states**: states where assignment probability ≥ threshold (see Section 4.2). A sample may have multiple active states.
- **assignment_certainty**: the maximum probability in the vector, reflecting how certain the model is in its primary assignment.

---

## 4. State Inference Rules

### 4.1 Unsupervised Clustering Approach

States are discovered using unsupervised clustering in embedding space. Implementation chooses the clustering algorithm (e.g., k‑means, Gaussian mixture, DBSCAN). This spec does not prescribe a specific algorithm.

- Clustering must operate only on embeddings. No labels, annotations, or external metadata are used.
- **Determinism**: Given the same embeddings, the same clustering algorithm, and the same random seed, the state inference process must yield identical states. Random seeds must be logged in the state model metadata.
- **Reproducibility**: The process must log all parameters (algorithm name, number of clusters, threshold, random seed). Re‑running with identical inputs and parameters must produce identical states and assignments.

### 4.2 Soft Assignment and Threshold Policy

- **Assignment Probabilities**: Each sample receives a probability vector across states, derived from the clustering model (e.g., mixture model posterior probabilities or distance‑based softmax). The exact method is an implementation detail.

- **Threshold**: A sample is considered active in a state if its assignment probability is ≥ 0.1. This constant threshold (10%) provides a balance between sensitivity and specificity.

- **Configurable Option**: If implementations allow different thresholds, the value must be recorded in the state model metadata and considered part of versioning. Changes require at least a minor version bump.

- **Boundary Rule**: A probability exactly equal to the threshold counts as active.

- **Primary State**: The state with the highest assignment probability for a sample. Even if the highest probability is below the threshold, the sample still has a primary state, but the assignment_certainty will be low.

### 4.3 Uncertainty Representation

- **assignment_uncertainty** describes variability of assignment probabilities across samples for each state. It must be expressed as statistical bounds (e.g., percentile range) and reported with the state object.

- **assignment_certainty** is recorded per sample. It can be used to filter low‑confidence assignments but must not be interpreted medically.

- **Distance Metrics** may be used internally to derive probabilities but are not exposed outside implementation.

### 4.4 State Drift Handling

- **Immutability**: Once a state model is created, its definitions are frozen. New data or methodological changes do not update states in place; they result in a new state model version.

- **Drift Detection**: Optionally, implementers may analyse how new data fits existing states. Criteria for drift (e.g., more than X% of samples change primary state or cluster variance exceeds a threshold) must be defined and logged. Exceeding drift criteria triggers a version increment.

- **Change Log**: All version changes must include a description of drift detection results, threshold changes, and any new parameters.

- **Scope**: State drift refers to static shifts in state definitions due to new data, not temporal transitions (handled in Phase 3).

---

## 5. Output Format Specification (Conceptual)

This section describes the conceptual structure of outputs from state inference. It is not an API contract but a guide for consistent representation.

### 5.1 Required Fields per State

- **state_id** – unique identifier (`state_{index}_v{version}`).
- **defining_features** – list of embedding dimension indices that characterise the state (no gene names).
- **stability_score** – float [0, 1] with accompanying disclaimer in any output that this value has no medical meaning.
- **variance_profile** – vector of variances across embedding dimensions.
- **assignment_uncertainty** – representation of uncertainty bounds for state assignments across samples.
- **version** – state model version string.
- **threshold** – active state threshold used (e.g., 0.1) if different from default.
- **random_seed** – seed used in clustering (ensuring reproducibility).
- **change_log** – summary of differences from previous version.

### 5.2 Required Fields per Sample Assignment

- **sample_id** – non‑identifying sample identifier.
- **state_probabilities** – vector of probabilities across states (summing to 1.0).
- **primary_state** – state_id with highest probability.
- **assignment_certainty** – maximum probability value.
- **active_states** – list of state_ids where probability ≥ threshold.
- **model_version** – version of the state model used for assignment.

### 5.3 Forbidden Fields in Outputs

- Any gene names or expression values.
- Any clinical, tissue, or condition labels.
- Any disease, health, or prognosis terminology.
- Any external annotations (gene ontology, pathways, etc.).

### 5.4 Optional Fields

- Visualization coordinates (e.g., PCA or UMAP coordinates), if available from Phase 1, for plotting purposes.
- Additional clustering statistics (e.g., silhouette score) only if they do not imply biological or medical interpretation.

All outputs must maintain neutral language and include stability score disclaimer.

---

## 6. State Comparison

- **Scope**: State comparison is limited to states within the same state model version. Comparing states across different versions is not supported. Cross‑version comparison may be introduced in a future phase with explicit version mapping and documentation.

- **Similarity/Dissimilarity Definition**: "Similar" states are those whose centroids are close in embedding space according to a distance metric (e.g., Euclidean distance). Similarity does not imply biological or functional similarity. It only reflects proximity in latent space.

- **Outputs**: Any state comparison output must include a disclaimer that the measure reflects embedding‑space distance, not biological or clinical relatedness.

---

## 7. Edge Cases and Validation Rules

Implementers must handle the following cases consistently:

- **Uniform Assignment**: If all samples have nearly uniform assignment probabilities (no clear clusters), the inference may return a single state or an "undefined" state. The system should log a warning and may require additional dimensionality reduction or threshold adjustments.

- **Single‑State Outcome**: If clustering finds only one state, this is valid but indicates no meaningful partitioning. Output should reflect a single state with assignment_certainty values near 1.0.

- **Excessive States**: If clustering yields more than, say, 50 states, implementations should treat this as an error or require manual intervention. Too many states compromise interpretability.

- **Low Confidence Assignments**: If assignment_certainty is below the threshold for all samples, the model should flag this and either increase threshold, change algorithm parameters, or abort inference with an error.

- **Missing or Corrupted Data**: Any missing embeddings, NaNs, or mismatched sample counts must cause a clear error with neutral messaging.

---

## 8. Scale Constraints (Guidance)

These are guidelines, not strict limits:

- **Number of Samples**: Designed to handle datasets from 100 up to 1,000,000 samples. Implementations should document tested ranges.

- **Number of States**: Typical models will discover 3–50 states. Values outside this range require justification and may require parameter adjustments.

- **Embedding Dimensions**: Phase 1 embeddings typically have 64–512 dimensions. State inference must support this range.

---

## 9. Visualization Scope

Phase 2 is responsible for data preparation for visualization, not rendering interactive UIs. Specifically:

- Provide coordinates (e.g., PCA/UMAP) and state assignments for plotting in external tools.
- Provide color assignments or labels corresponding to states.
- Do not implement interactive dashboards or UI components. Visualization UI will be handled in future phases.

---

## 10. Conceptual API Endpoints (Design Only)

To aid consistency in future implementation, the following conceptual endpoints are proposed. They define what operations Phase 2 should support, but their implementation is deferred:

- **POST /states/infer** – Accepts a reference to Phase 1 embeddings, performs state inference, and returns a new state model ID and summary. Requires input validation as described in Section 2.

- **GET /states/{state_model_id}** – Retrieves a state model's metadata, including definitions and core properties.

- **GET /states/{state_model_id}/assignments** – Retrieves the assignment probabilities, primary states, and assignment_certainty for each sample.

- **GET /states/{state_model_id}/compare** – Computes similarity/dissimilarity metrics between states within the same model. Returns distances with appropriate disclaimer.

These endpoints should return data structures conforming to the output format specification and should include stability score warnings.

---

## 11. Error Handling (Conceptual)

Phase 2 should define standard error conditions and responses:

- **Invalid Embeddings**: Wrong dimension, NaN or Inf values → return 400 error with neutral message.

- **Missing Metadata**: Required fields missing → return 400 error with list of missing keys.

- **Version Mismatch**: Embeddings and model version incompatible → return 400 error explaining mismatch.

- **Clustering Failure**: Clustering algorithm fails to converge → return 500 error with suggestion to adjust parameters.

- **Threshold Errors**: If the configured threshold is invalid (e.g., < 0 or > 1) → return 400 error.

Error messages must avoid any medical interpretation and guide the user to correct input problems.

---

## 12. Testing Requirements (Conceptual)

To ensure correct implementation, the following tests are recommended:

- **Determinism Tests** – Running state inference twice on the same embeddings with the same parameters and random seed must produce identical states and assignments.

- **Terminology Enforcement** – Validate that outputs and logs contain no forbidden medical or biological terms.

- **Edge Case Tests** – Test handling of uniform assignment distributions, single-state outcomes, too many states, low confidence assignments, and corrupted inputs.

- **Reproducibility Tests** – Validate that using the same embeddings and metadata across different environments yields the same results when the same random seed is used.

---

## 13. Misuse Prevention

To prevent misinterpretation and misuse of state outputs:

- **Disclaimers** – All outputs containing stability scores or state assignments must include the disclaimer: "These values are statistical properties of embedding clusters and have no medical or clinical meaning. Do not use for diagnosis, prognosis, or treatment decisions."

- **Forbidden Use** – Clients are prohibited from interpreting states as biological or health indicators, using them for diagnostic or therapeutic purposes, or claiming they correspond to known cell types.

- **Documentation** – Implementation documentation must reiterate non‑medical scope and reinforce neutral language.

---

## 14. Open Design Decisions

Certain design aspects remain open and will be resolved during implementation:

- **Clustering Algorithm Choice** – The specific unsupervised algorithm (k‑means, Gaussian mixture, spectral clustering, etc.) is undecided. The algorithm must satisfy determinism and reproducibility requirements.

- **Exact Statistical Measures** – Methods for calculating stability_score, variance_profile, assignment_uncertainty, and assignment_certainty may vary. Implementation must document choices and ensure they do not infer biological meaning.

- **Drift Detection Criteria** – The quantitative threshold (e.g., percentage of samples changing state) that triggers a new version is to be defined. Implementation must document rationale and log detection metrics.

- **Scaling Strategies** – Approaches for scaling to millions of samples (e.g., subsampling, distributed clustering) are open. Implementation will choose strategies consistent with reproducibility and determinism.

These open items must not be interpreted in ways that violate the non‑medical scope or other constraints. Decisions should be documented and versioned.

---

## 15. Summary

This revised specification addresses the critical and high‑priority issues identified in the hostile peer review. It clarifies ambiguous definitions, sets strict input validation, defines versioning and threshold policies, distinguishes uncertainty terms, specifies output formats, outlines edge‑case handling, and strengthens neutrality and reproducibility requirements. It adds guidelines for error handling, testing, visualization scope, scale constraints, misuse prevention, conceptual API endpoints, and open design decisions. By tightening these aspects, the Phase 2 design provides a robust, unambiguous foundation for future implementation while maintaining the non‑medical, purely observational intent of the RNA State Intelligence Platform.

---

**End of Phase 2 Design Specification (Revised)**

This document defines Phase 2 conceptually. Implementation will follow in a future phase, respecting PHASE1_FREEZE.md and this design specification.

**Revision History**:
- Initial version: Design specification
- Revised: Addressed critical and high-priority issues from hostile peer review
- Final revision: Incorporated structured feedback and tightened all ambiguous elements
- Status: Ready for implementation planning (no code yet)
